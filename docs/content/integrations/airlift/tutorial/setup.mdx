# Airflow Migration Tutorial: Setup

In this step, we'll

- Install the example code
- Set up a local environment
- Ensure we can run Airflow locally.

## Installation & Project Structure

First, clone the tutorial example repo locally, and enter the repo directory.

```bash
git clone git@github.com:dagster-io/airlift-migration-tutorial.git
cd airlift-migration-tutorial
```

Next, we'll create a fresh virtual environment using `uv`.

```bash
pip install uv
uv venv
source .venv/bin/activate
```

## Running Airflow locally

The tutorial example involves running a local Airflow instance. This can be done by running the following commands from the root of the `airlift-migration-tutorial` directory.

First, install the required python packages:

```bash
make airflow_install
```

Next, scaffold the Airflow instance, and initialize the dbt project:

```bash
make airflow_setup
```

Finally, run the Airflow instance with environment variables set:

```bash
make airflow_run
```

This will run the Airflow Web UI in a shell. You should now be able to access the Airflow UI at `http://localhost:8080`, with the default username and password set to `admin`.

You should be able to see the `rebuild_customers_list` DAG in the Airflow UI, made up of three tasks: `load_raw_customers`, `run_dbt_model`, and `export_customers`.

<Image
alt="rebuild_customers_list DAG"
src="/images/integrations/airlift/rebuild_customers_dag.png"
width={1484}
height={300}
/>

## Next Steps

The next step is to peer a Dagster installation with the Airflow Instance. [Click here](/integrations/airlift/tutorial/peer) to follow along for part 2.
